import google.generativeai as genai
from typing import Dict, List, Optional
from datetime import datetime, timedelta
from sqlalchemy.orm import Session
from ..database import SessionLocal
from .. import models
import json
import os
from dotenv import load_dotenv
import time
from .stock_agent import stock_agent
from .order_agent import order_agent
from .modify_agent import modify_agent
from .sales_agent import sales_agent

# Cargar variables de entorno
load_dotenv()

class ConversationManager:
    def __init__(self):
        self.memory_cache = {}  # Cache en memoria por n√∫mero de tel√©fono
        
        # ‚úÖ SISTEMA DE M√öLTIPLES API KEYS CON ROTACI√ìN
        self.api_keys = self._load_api_keys()
        self.current_key_index = 0
        self.key_retry_delays = {}  # Para tracking de delays por key
        
        if not self.api_keys:
            raise ValueError("No se encontraron GOOGLE_API_KEY en variables de entorno")
        
        # Configurar Gemini con la primera key v√°lida
        self._configure_gemini()
        
        print(f"üîë ConversationManager inicializado con {len(self.api_keys)} API keys")

    
    def _load_api_keys(self) -> List[str]:
        """Carga todas las API keys disponibles desde el .env"""
        api_keys = []
        
        # Buscar todas las keys que sigan el patr√≥n GOOGLE_API_KEY_X
        for i in range(1, 10):  # Buscar hasta GOOGLE_API_KEY_9
            key = os.getenv(f"GOOGLE_API_KEY_{i}")
            if key:
                api_keys.append(key)
                print(f"üîë API Key #{i} cargada: {key[:10]}...")
        
        # Tambi√©n buscar la key gen√©rica por compatibilidad
        generic_key = os.getenv("GEMINI_API_KEY")
        if generic_key and generic_key not in api_keys:
            api_keys.append(generic_key)
            print(f"üîë API Key gen√©rica cargada: {generic_key[:10]}...")
        
        return api_keys
    
    def _configure_gemini(self):
        """Configura Gemini con la API key actual"""
        current_key = self.api_keys[self.current_key_index]
        genai.configure(api_key=current_key)
        self.model = genai.GenerativeModel('gemini-1.5-flash')
        print(f"üîß Gemini configurado con API key #{self.current_key_index + 1}")
    
    def _switch_to_next_key(self):
        """Cambia a la siguiente API key disponible"""
        self.current_key_index = (self.current_key_index + 1) % len(self.api_keys)
        self._configure_gemini()
        print(f"üîÑ Cambiado a API key #{self.current_key_index + 1}")
    
    async def _make_gemini_request_with_fallback(self, prompt: str, **kwargs):
        """Hace petici√≥n a Gemini con fallback autom√°tico entre API keys"""
        
        max_retries = len(self.api_keys)  # Intentar con todas las keys
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                current_key_num = self.current_key_index + 1
                print(f"üîç Query Agent usando API Key #{current_key_num}")
                
                # Verificar si esta key tiene delay de retry
                key_id = f"key_{self.current_key_index}"
                if key_id in self.key_retry_delays:
                    retry_time = self.key_retry_delays[key_id]
                    if time.time() < retry_time:
                        print(f"‚è∞ API Key #{current_key_num} en cooldown hasta {datetime.fromtimestamp(retry_time)}")
                        self._switch_to_next_key()
                        retry_count += 1
                        continue
                
                # Intentar la petici√≥n
                response = self.model.generate_content(prompt, **kwargs)
                
                # Si llegamos aqu√≠, la petici√≥n fue exitosa
                # Limpiar cualquier delay previo para esta key
                if key_id in self.key_retry_delays:
                    del self.key_retry_delays[key_id]
                
                return response
                
            except Exception as e:
                error_str = str(e).lower()
                print(f"‚ùå Error con API key #{current_key_num}: {e}")
                
                # Verificar si es error de cuota
                if "quota" in error_str or "exceeded" in error_str or "429" in error_str:
                    print(f"üö´ API Key #{current_key_num} agot√≥ su cuota")
                    
                    # Poner esta key en cooldown por 1 hora
                    self.key_retry_delays[key_id] = time.time() + 3600
                    
                    # Cambiar a la siguiente key
                    self._switch_to_next_key()
                    retry_count += 1
                    continue
                    
                elif "rate limit" in error_str or "rate_limit" in error_str:
                    print(f"‚è≥ API Key #{current_key_num} tiene rate limiting")
                    
                    # Cooldown m√°s corto para rate limiting (5 minutos)
                    self.key_retry_delays[key_id] = time.time() + 300
                    
                    # Cambiar a la siguiente key
                    self._switch_to_next_key()
                    retry_count += 1
                    continue
                    
                else:
                    # Error no relacionado con cuota, intentar una vez m√°s con la siguiente key
                    print(f"üîÑ Error general, intentando con siguiente key")
                    self._switch_to_next_key()
                    retry_count += 1
                    continue
        
        # Si llegamos aqu√≠, todas las keys fallaron
        raise Exception(f"Todas las API keys ({len(self.api_keys)}) han fallado o est√°n en cooldown")

    async def process_message(self, phone: str, message: str) -> str:
        """Punto de entrada principal para procesar mensajes"""
        try:
            print(f"ü§ñ ConversationManager procesando: {phone} - {message}")
            
            # 1. Obtener conversaci√≥n completa
            conversation = await self.get_full_conversation(phone)
            
            # 2. Analizar intenci√≥n con contexto completo (con fallback de API keys)
            intent = await self.analyze_intent_with_context(message, conversation)
            
            # 3. Derivar al agente especializado
            response = await self.dispatch_to_specialized_agent(intent, message, conversation)
            
            # 4. Actualizar conversaci√≥n
            await self.update_conversation(phone, message, response, intent)
            
            return response
            
        except Exception as e:
            print(f"‚ùå Error en ConversationManager: {e}")
            return "Disculpa, tuve un problema t√©cnico. ¬øPodr√≠as repetir tu consulta?"
    
    async def get_full_conversation(self, phone: str) -> Dict:
        """Obtiene conversaci√≥n completa de BD + memoria"""
        
        # Verificar cache en memoria primero
        if phone in self.memory_cache:
            cached_conversation = self.memory_cache[phone]
            # Si el cache es reciente (menos de 10 minutos), usarlo
            if (datetime.now() - cached_conversation.get('last_updated', datetime.now())).seconds < 600:
                print(f"üíæ Usando conversaci√≥n en memoria para {phone}")
                return cached_conversation
        
        # Obtener de base de datos
        db = SessionLocal()
        try:
            # Buscar conversaci√≥n existente
            conversation_record = db.query(models.Conversation).filter(
                models.Conversation.user_phone == phone
            ).order_by(models.Conversation.created_at.desc()).first()
            
            # Buscar mensajes recientes (√∫ltimos 50)
            recent_messages = db.query(models.Message).filter(
                models.Message.user_phone == phone
            ).order_by(models.Message.timestamp.desc()).limit(50).all()
            
            # Buscar productos vistos recientemente (√∫ltima hora)
            one_hour_ago = datetime.now() - timedelta(hours=1)
            recent_searches = db.query(models.Message).filter(
                models.Message.user_phone == phone,
                models.Message.timestamp >= one_hour_ago,
                models.Message.role == 'assistant'
            ).limit(5).all()
            
            # Buscar pedidos recientes (√∫ltimos 7 d√≠as)  
            week_ago = datetime.now() - timedelta(days=7)
            recent_orders = db.query(models.Order).filter(
                models.Order.user_phone == phone,
                models.Order.created_at >= week_ago
            ).order_by(models.Order.created_at.desc()).limit(10).all()
            
            # Construir objeto de conversaci√≥n
            conversation = {
                'phone': phone,
                'conversation_id': conversation_record.id if conversation_record else None,
                'messages': [
                    {
                        'role': msg.role,
                        'content': msg.content,
                        'timestamp': msg.timestamp.isoformat(),
                        'intent': getattr(msg, 'intent', None)
                    } 
                    for msg in reversed(recent_messages)  # Orden cronol√≥gico
                ],
                'recent_searches': [
                    {
                        'content': msg.content,
                        'timestamp': msg.timestamp.isoformat()
                    }
                    for msg in recent_searches
                ],
                'recent_orders': [
                    {
                        'id': order.id,
                        'product_id': order.product_id,
                        'quantity': order.qty,
                        'status': order.status,
                        'created_at': order.created_at.isoformat(),
                        'buyer': order.buyer
                    }
                    for order in recent_orders
                ],
                'last_updated': datetime.now()
            }
            
            # Guardar en cache de memoria
            self.memory_cache[phone] = conversation
            
            print(f"üìö Conversaci√≥n cargada para {phone}: {len(conversation['messages'])} mensajes, {len(recent_orders)} pedidos")
            
            return conversation
            
        except Exception as e:
            print(f"‚ùå Error obteniendo conversaci√≥n: {e}")
            return {
                'phone': phone,
                'conversation_id': None,
                'messages': [],
                'recent_searches': [],
                'recent_orders': [],
                'last_updated': datetime.now()
            }
        finally:
            db.close()
    
    async def analyze_intent_with_context(self, message: str, conversation: Dict) -> str:
        """Analiza intenci√≥n del usuario con contexto completo"""
        
        try:
            # Crear prompt con contexto completo
            prompt = self.create_intent_analysis_prompt(message, conversation)
            
            # ‚úÖ USAR SISTEMA DE FALLBACK DE API KEYS
            response = await self._make_gemini_request_with_fallback(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.1,
                    max_output_tokens=50,
                )
            )
            
            intent = response.text.strip().lower()
            
            # ‚úÖ MEJORAR validaci√≥n de intenciones
            valid_intents = ['check_stock', 'create_order', 'modify_order', 'sales_advice', 'general_chat']
            
            if intent not in valid_intents:
                # Usar an√°lisis m√°s sofisticado
                intent = self._analyze_intent_fallback(message, conversation)
            
            print(f"üéØ Intenci√≥n detectada: {intent} para mensaje: '{message}'")
            return intent
            
        except Exception as e:
            print(f"‚ùå Error analizando intenci√≥n: {e}")
            return self._analyze_intent_fallback(message, conversation)

    def _analyze_intent_fallback(self, message: str, conversation: Dict) -> str:
        """An√°lisis de intenci√≥n m√°s robusto como fallback"""
        message_lower = message.lower()
        
        # An√°lisis contextual
        recent_messages = conversation.get('messages', [])[-3:]
        context_has_products = any('stock' in msg.get('content', '').lower() 
                                  for msg in recent_messages 
                                  if msg.get('role') == 'assistant')
        
        # Palabras clave m√°s espec√≠ficas
        stock_keywords = ['stock', 'cuanto', 'cu√°nto', 'ten√©s', 'disponible', 'colores', 'talles', 'qu√© hay']
        order_keywords = ['pedido', 'quiero', 'necesito', 'comprar', 'encargar', 'haceme']
        modify_keywords = ['cambiar', 'modificar', 'cancelar', 'editar']
        advice_keywords = ['recomend√°s', 'conviene', 'mejor', 'qu√©', 'para qu√©']
        
        # Detectar con prioridad contextual
        if any(word in message_lower for word in modify_keywords) and conversation.get('recent_orders'):
            return 'modify_order'
        elif any(word in message_lower for word in order_keywords):
            return 'create_order'
        elif any(word in message_lower for word in stock_keywords):
            return 'check_stock'
        elif any(word in message_lower for word in advice_keywords):
            return 'sales_advice'
        else:
            return 'general_chat'
    
    def create_intent_analysis_prompt(self, message: str, conversation: Dict) -> str:
        """Crea prompt para an√°lisis de intenci√≥n"""
        
        # Formatear mensajes recientes para contexto
        recent_messages = ""
        for msg in conversation.get('messages', [])[-5:]:  # √öltimos 5 mensajes
            role = "Usuario" if msg['role'] == 'user' else "Bot"
            recent_messages += f"{role}: {msg['content']}\n"
        
        # Informaci√≥n de pedidos recientes
        recent_orders_info = ""
        if conversation.get('recent_orders'):
            recent_orders_info = f"Pedidos recientes: {len(conversation['recent_orders'])} en la √∫ltima semana"
        
        return f"""Eres un dispatcher inteligente para un sistema de ventas B2B textil.

CONVERSACI√ìN RECIENTE:
{recent_messages}

√öLTIMO MENSAJE DEL USUARIO: "{message}"

{recent_orders_info}

Analiza la intenci√≥n y responde SOLO con UNA de estas opciones:

check_stock - Si pregunta por:
- Stock disponible, inventario, cantidades
- Colores, talles, tipos de productos
- "¬øqu√© ten√©s?", "cu√°nto stock?", "qu√© colores hay?"

create_order - Si quiere hacer pedido:
- "quiero X unidades", "haceme el pedido", "necesito comprar"
- Especifica cantidad + producto
- "generame el pedido", "confirmar pedido"

modify_order - Si quiere cambiar pedido existente:
- "cambiar cantidad", "modificar pedido", "cancelar"
- Se refiere a pedidos ya hechos

sales_advice - Si pide consejos/recomendaciones:
- "qu√© me recomend√°s?", "para qu√© sirve?", "mejor opci√≥n"
- Consultas sobre uso, calidad, aplicaci√≥n

general_chat - Para saludos, charla general:
- "hola", "gracias", "c√≥mo est√°s", "chau"
- Conversaci√≥n social

IMPORTANTE: 
- Considera el CONTEXTO completo, no solo el √∫ltimo mensaje
- Si despu√©s de mostrar productos dice "quiero X cantidad" = create_order
- Si pregunta por stock espec√≠fico despu√©s de ver productos = check_stock

Respuesta (solo la intenci√≥n):"""

    async def dispatch_to_specialized_agent(self, intent: str, message: str, conversation: Dict) -> str:
        """Deriva al agente especializado seg√∫n la intenci√≥n"""
        
        try:
            print(f"üîÄ Derivando a agente: {intent}")
            
            if intent == 'check_stock':
                # ‚úÖ USAR STOCK AGENT REAL
                return await stock_agent.handle_stock_query(message, conversation)
                
            elif intent == 'create_order':
                # ‚úÖ USAR ORDER AGENT REAL
                return await order_agent.handle_order_creation(message, conversation)
                
            elif intent == 'modify_order':
                # ‚úÖ USAR MODIFY AGENT REAL
                return await modify_agent.handle_order_modification(message, conversation)
                
            elif intent == 'sales_advice':
                # ‚úÖ USAR SALES AGENT REAL
                return await sales_agent.handle_sales_advice(message, conversation)
                
            else:  # general_chat
                return await self.handle_general_chat_temp(message, conversation)
                
        except Exception as e:
            print(f"‚ùå Error en dispatch: {e}")
            return "Disculpa, tuve un problema procesando tu consulta. ¬øPodr√≠as intentar de nuevo?"
    
    async def handle_general_chat_temp(self, message: str, conversation: Dict) -> str:
        """Manejo temporal de charla general"""
        current_key_num = self.current_key_index + 1
        return f"¬°Hola! Soy Ventix, tu asistente de ventas textiles. ¬øEn qu√© puedo ayudarte hoy?\n\n‚öôÔ∏è Sistema activo con API Key #{current_key_num}\n\nüéØ Puedo mostrarte productos, consultar stock o ayudarte a hacer pedidos."
    
    async def update_conversation(self, phone: str, user_message: str, bot_response: str, intent: str):
        """Actualiza la conversaci√≥n en BD y memoria"""
        
        db = SessionLocal()
        try:
            # Buscar o crear conversaci√≥n
            conversation_record = db.query(models.Conversation).filter(
                models.Conversation.user_phone == phone
            ).first()
            
            if not conversation_record:
                conversation_record = models.Conversation(
                    user_phone=phone,
                    created_at=datetime.now()
                )
                db.add(conversation_record)
                db.commit()
                db.refresh(conversation_record)
            
            # Guardar mensaje del usuario
            user_msg = models.Message(
                conversation_id=conversation_record.id,
                user_phone=phone,
                role='user',
                content=user_message,
                intent=intent,
                timestamp=datetime.now()
            )
            db.add(user_msg)
            
            # Guardar respuesta del bot
            bot_msg = models.Message(
                conversation_id=conversation_record.id,
                user_phone=phone,
                role='assistant',
                content=bot_response,
                timestamp=datetime.now()
            )
            db.add(bot_msg)
            
            db.commit()
            
            # Actualizar cache en memoria
            if phone in self.memory_cache:
                self.memory_cache[phone]['messages'].extend([
                    {
                        'role': 'user',
                        'content': user_message,
                        'timestamp': datetime.now().isoformat(),
                        'intent': intent
                    },
                    {
                        'role': 'assistant', 
                        'content': bot_response,
                        'timestamp': datetime.now().isoformat(),
                        'intent': None
                    }
                ])
                self.memory_cache[phone]['last_updated'] = datetime.now()
            
            print(f"üíæ Conversaci√≥n actualizada para {phone}")
            
        except Exception as e:
            print(f"‚ùå Error actualizando conversaci√≥n: {e}")
            db.rollback()
        finally:
            db.close()

# Instancia global
conversation_manager = ConversationManager()